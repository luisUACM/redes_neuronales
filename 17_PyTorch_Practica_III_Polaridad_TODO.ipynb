{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica III: Clasificación multiclase con embeddings\n",
    "\n",
    "1. Implementar arquitecturas de redes FeedForward (MLP) con PyTorch para clasificación basado en el dataset de polaridad\n",
    "\n",
    "2. Evaluar el desempeño de varias arquitecturas de redes FeedForward con diferentes capas y diferentes modelos de embeddings.\n",
    "\n",
    "    2.1. Hacer una separación de datos 80% para entrenamiento y 20% para test con el conjunto de datos de polaridad en español (clasificador multiclase)\n",
    "    \n",
    "    Nota: Utilizar la transformación de sentencias a vectores densos: embeddings\n",
    "\n",
    "    2.2. Separar el conjunto de entrenamiento en entrenamiento y validación:  Entrenamiento 90% y validación 10%. Para identificar cómo se desempeña el modelo durante su entrenamiento.\n",
    "\n",
    "    2.3. Usar la función de pérdida CrossEntropy, codificación one-hot para la representación de clases,  y el optimizador Adam.\n",
    "\n",
    "    2.4. Evaluar el desempeño con arquitecturas con una capa de entrada, capas ocultas con 2, 3, 4 y 5 capas ocultas y una capa de salida para clasificación multiclase.\n",
    "\n",
    "    2.5. Para cada una de las diferentes arquitecturas se probarán con los siguientes modelos pre-entrenados para español\n",
    "\n",
    "        2.5.1 Evaluar con Modelo de FastText Dominio General\n",
    "\n",
    "    [https://fasttext.cc/docs/en/crawl-vectors.html](https://fasttext.cc/docs/en/crawl-vectors.html#models)\n",
    "\n",
    "    Modelo en español (4.5 GB)->[Descarga](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.bin.gz)\n",
    "\n",
    "        2.5.2 Evaluar con Modelo de FastText dominio de Tweets para español de España\n",
    "    \n",
    "    [https://ingeotec.github.io/regional-spanish-models](https://ingeotec.github.io/regional-spanish-models/#resources)\n",
    "\n",
    "    Modelo de España (3.78 GB)->[Descarga](http://geo.ingeotec.mx/~sadit/regional-spanish-models/ES.bin)\n",
    "\n",
    "        2.5.3 Evaluar con Modelo de FastText dominio de Tweets para español de México\n",
    "\n",
    "    [https://ingeotec.github.io/regional-spanish-models](https://ingeotec.github.io/regional-spanish-models/#resources)\n",
    "\n",
    "    Modelo de México (3.46 GB)->[Descarga](http://geo.ingeotec.mx/~sadit/regional-spanish-models/MX.bin)\n",
    "\n",
    "3. Reportar los resultados de los experimentos con las métricas: Accuracy, Precisión, Recall y F1-Score\n",
    "\n",
    "    3.1 Discutir los resultados obtenidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de los datos y minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "#cargar los datos\n",
    "dataset = pd.read_json(\"./data/data_polaridad_es.json\", lines=True)\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset.klass.value_counts())\n",
    "# Extracción de los textos en arreglos de numpy\n",
    "X = dataset['text'].to_numpy()\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y = dataset['klass'].to_numpy()\n",
    "\n",
    "\n",
    "# TODO: Cargar el modelo de embeddings\n",
    "\n",
    "\n",
    "# TODO: Convertir los datos en vectores de embeddings\n",
    "\n",
    "\n",
    "# TODO: Crear la matriz de vectores de embeddings \n",
    "\n",
    "\n",
    "\n",
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Dividir el conjunto de entrenamiento en:  entrenamiento (90%) y validación (10%)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Codificar las clases de entrenamiento en formato one-hot \n",
    "\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class FF(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # TODO: Definición de capas, funciones de activación e inicialización de pesos\n",
    "\n",
    "        # TODO: Inicializar pesos con inicialización de Xavier\n",
    "        \n",
    "        # TODO: Inicializar bias a ceros\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        out= None\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Establecer los parámetros de la red\n",
    "\n",
    "# Parámetros de la red\n",
    "input_size =  0 # tamaño de los datos de entrada X\n",
    "\n",
    "output_size = 3   # 3 clases codificado en one-hot\n",
    "\n",
    "epochs = 10 # variar el número de épocas, para probar que funciona la programación \n",
    "                 # solo usar 2 épocas, para entrenamiento total usar por ejemplo entre 10 y 100 épocas\n",
    "learning_rate = 0.01 # Generalmente se usan learning rate pequeños (0.001), \n",
    "\n",
    "# Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "# Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "batch_size = 64 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "# TODO: Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "\n",
    "\n",
    "# Crear la red\n",
    "model = FF(input_size, output_size)\n",
    "\n",
    "# Definir la función de pérdida\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Definir el optimizador\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# TODO: Entrenamiento y evaluación de la red con el conjunto de validación\n",
    "print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo para predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluar el desempeño de la red con el conjunto de test con representación de embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "# classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(Y_test, y_pred_test2))\n",
    "print(classification_report(Y_test, y_pred_test2, digits=4, zero_division='warn'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
