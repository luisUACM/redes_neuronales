{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica II: Clasificación multiclase\n",
    "\n",
    "1. Implementar arquitecturas de redes FeedForward con PyTorch para clasificación basado en el dataset de polaridad\n",
    "\n",
    "2. Evaluar el desempeño de varias arquitecturas de redes FeedForward con diferentes capas y tipos de preprocesamientos y características.\n",
    "\n",
    "    2.1. Hacer una separación de datos 80% para entrenamiento y 20% para test con el conjunto de datos de polaridad en español (clasificador multiclase)\n",
    "    Preprocesamientos generales:\n",
    "    convertir textos a minúsculas\n",
    "    borrar números\n",
    "    borrar puntuación\n",
    "    borrar símbolos\n",
    "    reducir  caracteres  duplicados a máximo 2\n",
    "\n",
    "    Nota: Utilizar un pesado de TF-IDF para la matriz de Document- Término (TfidfVectorizer)\n",
    "\n",
    "    2.2. Separar el conjunto de entrenamiento en entrenamiento y validación:  Entrenamiento 90% y validación 10%. Para identificar cómo se desempeña el modelo durante su entrenamiento.\n",
    "\n",
    "    2.3. Usar la función de pérdida CrossEntropy, codificación one-hot para la representación de clases,  y el optimizador Adam.\n",
    "\n",
    "    2.4. Evaluar el desempeño con arquitecturas con una capa de entrada, capas ocultas con 2, 3, 4 y 5 capas ocultas y una capa de salida para clasificación multiclase.\n",
    "\n",
    "    2.5. Para cada una de las diferentes arquitecturas se probarán con los siguientes preprocesamientos\n",
    "\n",
    "        2.5.1 Evaluación con unigramas\n",
    "\n",
    "        2.5.2 Evaluación con unigramas y bigramas\n",
    "\n",
    "        2.5.3 Evaluación con unigramas y stemming\n",
    "        \n",
    "        2.5.4 Evaluación con unigramas y bigramas y stemming (antes de crear los bigramas aplicar el stemming)\n",
    "\n",
    "3. Reportar los resultados de los experimentos con las métricas: Accuracy, Precisión, Recall y F1-Score\n",
    "\n",
    "    3.1 Discutir los resultados obtenidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de los datos y minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "#cargar los datos\n",
    "dataset = pd.read_json(\"./data/data_polaridad_es.json\", lines=True)\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset.klass.value_counts())\n",
    "# Extracción de los textos en arreglos de numpy\n",
    "X = dataset['text'].to_numpy()\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y = dataset['klass'].to_numpy()\n",
    "\n",
    "\n",
    "# TODO: Definir las funciones de preprocesamiento de texto vinculadas al proceso de creación de la matriz \n",
    "# Documento-Término creada con TfidfVectorizer.\n",
    "\n",
    "\n",
    "# TODO: Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "\n",
    "\n",
    "\n",
    "#  TODO: Dividir el conjunto de entrenamiento en:  entrenamiento (90%) y validación (10%)\n",
    "\n",
    "\n",
    "# TODO: Crear la matriz Documento-Término con el dataset de entrenamiento: tfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Codificar las clases de salida con la codificación One-hot para las salidas esperadas:  Y_train, Y_test y Y_val. 3 clases para cada subconjunto de valores esperados.\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Codificar las clases de salida con la codificación One-hot para las salidas esperadas:  Y_train, Y_test y Y_val. 3 clases para cada subconjunto de valores esperados.\n",
    "\n",
    "\n",
    "# TODO: Tranformar los datos de validación al espacio de representación del entrenamiento, esto es, usar el objeto tfidfVectorizer\n",
    "\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class FF(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # TODO: Definición de capas, funciones de activación e inicialización de pesos\n",
    "\n",
    "        # TODO: Inicializar pesos con inicialización de Xavier\n",
    "        \n",
    "        # TODO: Inicializar bias a ceros\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        out= None\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Establecer los parámetros de la red\n",
    "\n",
    "# Parámetros de la red\n",
    "input_size =  0 # tamaño de los datos de entrada X\n",
    "\n",
    "output_size = 3   # 3 clases codificado en one-hot\n",
    "\n",
    "epochs = 10 # variar el número de épocas, para probar que funciona la programación \n",
    "                 # solo usar 2 épocas, para entrenamiento total usar por ejemplo entre 10 y 100 épocas\n",
    "learning_rate = 0.01 # Generalmente se usan learning rate pequeños (0.001), \n",
    "\n",
    "# Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "# Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "batch_size = 64 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "# TODO: Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "\n",
    "# Crear la red\n",
    "model = FF(input_size, output_size)\n",
    "\n",
    "# Definir la función de pérdida\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Definir el optimizador\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "\n",
    "# TODO: Estas variables deben estar en el formato correcto para el entrenamiento\n",
    "X_train_TFIDF = None   # Datos de entrenamiento\n",
    "Y_train_ONE_HOT = None     # Etiquetas esperadas en formato one-hot\n",
    "X_val_TFIDF = None       # Datos de evualción para validación  del modelo\n",
    "Y_val = None            # Etiquetas esperadas en formato one-hot\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "   # Poner el modelo en modo de entrenamiento para cada iteración, ya que se evalua el modelo y se cambia el estatus a eval\n",
    "    model.train()  \n",
    "    lossTotal = 0\n",
    "    #definir el batch_size\n",
    "    dataloader = create_minibatches(X_train_TFIDF, Y_train_ONE_HOT, batch_size=batch_size)\n",
    "    for X_tr, y_tr in dataloader:\n",
    "        # inicializar los gradientes en cero para cada época\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Propagación hacia adelante\n",
    "        y_pred = model(X_tr)  #invoca al método forward de la clase MLP\n",
    "        # Calcular el error CrossEntropy\n",
    "        loss = criterion(y_pred, y_tr)\n",
    "        #Acumular el error \n",
    "        lossTotal += loss.item()\n",
    "        \n",
    "        # Propagación hacia atrás: cálculo de los gradientes de los pesos y bias\n",
    "        loss.backward()\n",
    "        \n",
    "        # actualización de los pesos: regla de actualización basado en el gradiente:\n",
    "        #  \n",
    "        optimizer.step()\n",
    "        if np.random.random() < 0.1:\n",
    "            print(f\"Batch Error : {loss.item()}\")\n",
    "\n",
    "    print(f\"Época {epoch+1}/{epochs}, Pérdida: {lossTotal/len(dataloader)}\")\n",
    "    \n",
    "    # Evaluar el modelo con el conjunto de validación\n",
    "    model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "    with torch.no_grad():  # No  calcular gradientes \n",
    "        y_pred = model(X_val_TFIDF)\n",
    "        # Obtiene una única clase, la más probable, el mayor valor\n",
    "        # argmax devuelve el índice que tiene el valor mayor del arreglo\n",
    "        # el índice representa la clase predicha debido a la codificación one-hot. \n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "        print(f\"Época {epoch+1}/{epochs}\")\n",
    "        print(\"P=\", precision_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"R=\", recall_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"F1=\", f1_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"Acc=\", accuracy_score(Y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo para evaluación de datos en el conjunto de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transformar el dataset de test con los mismos preprocesamientos y al  espacio de \n",
    "# representación vectorial que el modelo entrenado, es decir, al espacio de la matriz TFIDF\n",
    "\n",
    "# TODO: Estas variables deben estar en el formato correcto para el entrenamiento\n",
    "X_test_TFIDF = None       # Datos de entrenamiento\n",
    "Y_test = None             # Etiquetas esperadas en formato one-hot\n",
    "\n",
    "\n",
    "# Convertir los datos de prueba a tensores de PyTorch\n",
    "\n",
    "# Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    y_pred_test = model(X_test_TFIDF)\n",
    "\n",
    "# y_test_pred contiene las predicciones\n",
    "\n",
    "# Obtener la clase real\n",
    "y_pred_test = torch.argmax(y_pred_test, dim=1)\n",
    "\n",
    "print(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "# classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(Y_test, y_pred_test))\n",
    "print(classification_report(Y_test, y_pred_test, digits=4, zero_division='warn'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_new_data = [\"Tengo nuevo celular gracias\", \"se descompuso la pantalla del celular ya  no me funciona\", \"mi app de calendario no sirve\"]\n",
    "#TODO: transformar el arreglo x_new_data al espacio de representación vectorial con el objeto que se creo del tfidfVectorizer, en este ejemplo: vec_tfidf\n",
    "\n",
    "x_new_data_tfidf = vec_tfidf.transform(x_new_data)\n",
    "\n",
    "X_new_t = torch.from_numpy(x_new_data_tfidf.toarray())\n",
    "X_new_t = X_new_t.to(torch.float32)\n",
    "\n",
    "model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    y_pred = model(X_new_t)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    #TODO: transformar los valores de y_pred al texto original de la clase: positivo, negativo, neutro por medio del objeto del LabelEncoder, en este ejemplo: le\n",
    "    print(le.inverse_transform(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
