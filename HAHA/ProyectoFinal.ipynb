{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88480672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/luis-\n",
      "[nltk_data]     beto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import fasttext\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from os import putenv\n",
    "from tqdm import trange\n",
    "from torch import Tensor\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from torch.nn.functional import one_hot\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "#Para usar AMD GPU's con ROC\n",
    "putenv(\"HSA_OVERRIDE_GFX_VERSION\", \"10.3.0\")\n",
    "\n",
    "EXPERIMENTAR = True\n",
    "NUM_CLASES = 2\n",
    "RANDOM_STATE = 45\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = stopwords.words(\"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4844ad",
   "metadata": {},
   "source": [
    "<h1>Arquitectura de capas completamente conectadas</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac371dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, hiden_sizes: list[int], output_size: int):\n",
    "        super().__init__()\n",
    "        self.fcl = nn.ModuleList()\n",
    "        self.act = nn.ModuleList()\n",
    "        self.drop = nn.ModuleList()\n",
    "        self.drop.append(nn.Dropout(0.2)) #Input layer\n",
    "        \n",
    "        # Las capas se forman por pares de numeros, en total 1 par menos que la lista neuronas\n",
    "        neuronas = [input_size] + hiden_sizes + [output_size]\n",
    "        for i in range(len(neuronas) - 1):\n",
    "            self.fcl.append(nn.Linear(neuronas[i], neuronas[i + 1]))\n",
    "            nn.init.xavier_uniform_(self.fcl[i].weight)                                                                                                 # type: ignore\n",
    "            nn.init.zeros_(self.fcl[i].bias)                                                                                                            # type: ignore\n",
    "        #Al aplicar CrossEntropy se necesita una función de activación menos que de capas\n",
    "        for i in range(len(neuronas) - 2):\n",
    "            self.act.append(nn.ReLU())\n",
    "            self.drop.append(nn.Dropout())\n",
    "    \n",
    "    def forward(self, X):\n",
    "        x = X\n",
    "        for i in range(len(self.act)):\n",
    "            x = self.drop[i](x)\n",
    "            x = self.fcl[i](x)\n",
    "            x = self.act[i](x)\n",
    "            \n",
    "        x = self.fcl[-1](x)     #No activar la última capa ni hacer dropout\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43cebb",
   "metadata": {},
   "source": [
    "<h1>Funciones de utilidad</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9a7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_texto(input_str,\n",
    "                    punct=False,\n",
    "                    accents=False,\n",
    "                    num=False,\n",
    "                    max_dup=2):\n",
    "    \"\"\"\n",
    "        punct=False (elimina la puntuación, True deja intacta la puntuación)\n",
    "        accents=False (elimina los acentos, True deja intactos los acentos)\n",
    "        num= False (elimina los números, True deja intactos los acentos)\n",
    "        max_dup=2 (número máximo de símbolos duplicados de forma consecutiva, rrrrr => rr)\n",
    "    \"\"\"\n",
    "    PUNCTUACTION = \";:,.\\\\-\\\"'/\"\n",
    "    SYMBOLS = \"()[]¿?¡!{}~<>|\"\n",
    "    NUMBERS= \"0123456789\"\n",
    "    SKIP_SYMBOLS = set(PUNCTUACTION + SYMBOLS)\n",
    "\n",
    "    nfkd_f = unicodedata.normalize('NFKD', input_str)\n",
    "    n_str = []\n",
    "    c_prev = ''\n",
    "    cc_prev = 0\n",
    "    for c in nfkd_f:\n",
    "        if not num:\n",
    "            if c in NUMBERS:\n",
    "                continue\n",
    "        if not punct:\n",
    "            if c in SKIP_SYMBOLS:\n",
    "                continue\n",
    "        if not accents and unicodedata.combining(c):\n",
    "            continue\n",
    "        if c_prev == c:\n",
    "            cc_prev += 1\n",
    "            if cc_prev >= max_dup:\n",
    "                continue\n",
    "        else:\n",
    "            cc_prev = 0\n",
    "        n_str.append(c)\n",
    "        c_prev = c\n",
    "    texto = unicodedata.normalize('NFKD', \"\".join(n_str))\n",
    "    texto = re.sub(r'(\\s)+', r' ', texto.strip(), flags=re.IGNORECASE)\n",
    "    return texto\n",
    "\n",
    "def eliminar_stopwords(texto: str):\n",
    "    tokens = [t for t in texto.split() if t not in STOPWORDS]\n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "def aplicar_stemming(texto: str):\n",
    "    stemmer = SnowballStemmer(\"spanish\")\n",
    "    tokens = [stemmer.stem(t) for t in texto.split()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocesar(texto: str):\n",
    "    texto = normaliza_texto(texto)\n",
    "    return texto\n",
    "\n",
    "def leer_datos(filename, raw=False):\n",
    "    dataset = pd.read_json(filename, lines=True)\n",
    "    X = dataset['text']\n",
    "    if not raw:\n",
    "        X = X.to_numpy()\n",
    "    Y = dataset['klass'].to_numpy()\n",
    "    return X, Y\n",
    "\n",
    "def leer_datos_embeddings(filename, variante: str):\n",
    "    dataset = pd.read_json(filename, lines=True)\n",
    "    \n",
    "    Y = dataset['klass'].to_numpy()\n",
    "    \n",
    "    if variante == 'MX':\n",
    "        X = dataset['we_mx'].to_numpy()\n",
    "    elif variante == 'ES':\n",
    "        X = dataset['we_es'].to_numpy()\n",
    "    else:\n",
    "        X = dataset['we_ft'].to_numpy()\n",
    "    return np.array(X.tolist()), Y\n",
    "\n",
    "def vectorizar_TF_IDF(X: list, ngram_range=(1,2), max_features=None):   \n",
    "    vec = TfidfVectorizer(analyzer='word', preprocessor=preprocesar, ngram_range=ngram_range, max_features=max_features)\n",
    "    X_ = [vec.fit_transform(X[0])]\n",
    "    for x in X[1:]:\n",
    "        X_.append(vec.transform(x))\n",
    "    return X_\n",
    "\n",
    "def vectorizar_embeddings(X: list, variante: str):\n",
    "    if variante == 'MX':\n",
    "        ft = fasttext.load_model('./fasttext/MX.bin')\n",
    "    elif variante == 'ES':\n",
    "        ft = fasttext.load_model('./fasttext/ES.bin')\n",
    "    elif variante == 'GEN':\n",
    "        ft = fasttext.load_model('./fasttext/cc.es.300.bin')\n",
    "    \n",
    "    res = []\n",
    "    i=0\n",
    "    for lista in X:\n",
    "        print('Antes' ,i)\n",
    "        X_ = lista.map(lambda x : ft.get_sentence_vector(x)) # type: ignore\n",
    "        X_ = np.vstack(X_.to_numpy())\n",
    "        res.append(X_)\n",
    "        print('DEspues' ,i)\n",
    "        i+=1\n",
    "    return res\n",
    "    \n",
    "def split(X, Y, test=0, test_size=0.2, val=0, val_size=0.1):\n",
    "    if test > 0:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, stratify=Y, random_state=RANDOM_STATE)\n",
    "        if val > 0:\n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=val_size, stratify=Y_train, random_state=RANDOM_STATE)\n",
    "            return X_train, Y_train, X_test, Y_test, X_val, Y_val\n",
    "        else:\n",
    "            return X_train, Y_train, X_test, Y_test\n",
    "    elif val > 0:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=val_size, stratify=Y, random_state=RANDOM_STATE)\n",
    "        return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def balancear(X, Y):\n",
    "    sampler = SMOTE(sampling_strategy='minority')   \n",
    "    return sampler.fit_resample(X, Y)\n",
    "    \n",
    "def torchificar(X: list, Y: list, representacion: str, one_hot_encoding=True, decode=False):\n",
    "    X_torch = []\n",
    "    Y_torch = []\n",
    "    if decode:\n",
    "        le = LabelEncoder()\n",
    "    \n",
    "    for x in X:\n",
    "        if representacion == 'TF-IDF':\n",
    "            x_np = x.toarray().astype(np.float32)\n",
    "        elif representacion == 'Embeddings':\n",
    "            x_np = x.astype(np.float32)\n",
    "        x_torch = torch.from_numpy(x_np)                                                                                                            # type: ignore\n",
    "        if torch.cuda.is_available():\n",
    "            x_torch = x_torch.cuda()\n",
    "        X_torch.append(x_torch)\n",
    "    \n",
    "    for y in Y:\n",
    "        if decode:\n",
    "            y_ = le.fit_transform(y)                                                                                                                # type: ignore\n",
    "        else:\n",
    "            y_ = y\n",
    "        y_torch = torch.from_numpy(y_)\n",
    "        if torch.cuda.is_available():\n",
    "            y_torch = y_torch.cuda()\n",
    "        Y_torch.append(y_torch)\n",
    "    \n",
    "    if one_hot_encoding:\n",
    "        Y_torch[0] = one_hot(Y_torch[0], num_classes=NUM_CLASES).float()\n",
    "    \n",
    "    return X_torch, Y_torch\n",
    "\n",
    "def create_minibatches(X, Y, batch_size, X2=None):\n",
    "    if X2 == None:\n",
    "        dataset = TensorDataset(X, Y)\n",
    "    else:\n",
    "        dataset = TensorDataset(X, X2, Y)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "def entrenar(X_train, Y_train, modelo: nn.Module, optimizador: optim.Optimizer, funcion_perdida,\n",
    "    evaluar=True,\n",
    "    X_val = None,\n",
    "    Y_val = None,\n",
    "    verbose=False,\n",
    "    epocas=100,\n",
    "    batch_size=32,\n",
    "    error_minimo=0.02,\n",
    "    rango_epocas=5,\n",
    "    umbral_mejora=0.003\n",
    "    ):\n",
    "    \n",
    "    historial_perdida = []\n",
    "    historial_f1 = []\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        modelo.cuda()\n",
    "            \n",
    "    for _ in trange(epocas, desc=f'Entrenando'):\n",
    "        modelo.train()\n",
    "        lossTotal = 0\n",
    "        dataloader = create_minibatches(X_train, Y_train, batch_size=batch_size)\n",
    "        \n",
    "        for X_tr, Y_tr in dataloader:\n",
    "            optimizador.zero_grad()\n",
    "            Y_pred = modelo(X_tr)\n",
    "            loss = funcion_perdida(Y_pred, Y_tr)\n",
    "            Y_pred = torch.softmax(Y_pred, dim=1)\n",
    "            Y_pred = torch.argmax(Y_pred, dim=1)\n",
    "            lossTotal += loss.item()\n",
    "            loss.backward()\n",
    "            optimizador.step()\n",
    "                    \n",
    "        perdida = lossTotal/len(dataloader)\n",
    "        historial_perdida.append(perdida)\n",
    "        if evaluar:\n",
    "            f1, _, _, _ = test(X_val, Y_val, modelo)\n",
    "            historial_f1.append(f1)\n",
    "        \n",
    "            if verbose:\n",
    "                print('Pérdida: ', perdida)\n",
    "                print('F1-score: ', f1)\n",
    "        \n",
    "        stop = detener_entrenamiento(historial_perdida, error_minimo, rango_epocas, umbral_mejora)\n",
    "        if stop != None:\n",
    "            print(stop)\n",
    "            break\n",
    "    \n",
    "    return historial_perdida, historial_f1\n",
    "\n",
    "def entrenar_fused(X_train_tfidf, X_train_we, Y_train, modelo: nn.Module, optimizador: optim.Optimizer, funcion_perdida,\n",
    "    evaluar=True,\n",
    "    X_val_tfidf = None,\n",
    "    X_val_we = None,\n",
    "    Y_val = None,\n",
    "    verbose=False,\n",
    "    epocas=100,\n",
    "    batch_size=32,\n",
    "    error_minimo=0.02,\n",
    "    rango_epocas=5,\n",
    "    umbral_mejora=0.003\n",
    "    ):\n",
    "    \n",
    "    historial_perdida = []\n",
    "    historial_f1 = []\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        modelo.cuda()\n",
    "            \n",
    "    for _ in trange(epocas, desc=f'Entrenando'):\n",
    "        modelo.train()\n",
    "        lossTotal = 0\n",
    "        dataloader = create_minibatches(X_train_tfidf, Y_train, batch_size=batch_size, X2=X_train_we)\n",
    "        \n",
    "        for X_tr_tfidf, X_tr_we, Y_tr in dataloader:\n",
    "            optimizador.zero_grad()\n",
    "            Y_pred = modelo(X_tr_tfidf, X_tr_we)\n",
    "            loss = funcion_perdida(Y_pred, Y_tr)\n",
    "            Y_pred = torch.softmax(Y_pred, dim=1)\n",
    "            Y_pred = torch.argmax(Y_pred, dim=1)\n",
    "            lossTotal += loss.item()\n",
    "            loss.backward()\n",
    "            optimizador.step()\n",
    "                    \n",
    "        perdida = lossTotal/len(dataloader)\n",
    "        historial_perdida.append(perdida)\n",
    "        if evaluar:\n",
    "            f1, _, _, _ = test_fused(X_val_tfidf, X_val_we, Y_val, modelo)\n",
    "            historial_f1.append(f1)\n",
    "        \n",
    "            if verbose:\n",
    "                print('Pérdida: ', perdida)\n",
    "                print('F1-score: ', f1)\n",
    "        \n",
    "        stop = detener_entrenamiento(historial_perdida, error_minimo, rango_epocas, umbral_mejora)\n",
    "        if stop != None:\n",
    "            print(stop)\n",
    "            break\n",
    "    \n",
    "    return historial_perdida, historial_f1\n",
    "\n",
    "def detener_entrenamiento(historial_perdida: list, error_minimo, rango_epocas, umbral_mejora):\n",
    "    motivo_stop = None\n",
    "    \n",
    "    if historial_perdida[-1] < error_minimo:\n",
    "        motivo_stop = 'Paro por error mínimo'\n",
    "    elif len(historial_perdida) > 2 * rango_epocas:\n",
    "        error_rango_anterior = np.mean(historial_perdida[-2 * rango_epocas : -rango_epocas])\n",
    "        error_rango_actual = np.mean(historial_perdida[-rango_epocas:])\n",
    "        mejora = error_rango_anterior - error_rango_actual\n",
    "        if mejora < umbral_mejora:\n",
    "            motivo_stop = 'Paro por falta de mejora'\n",
    "    \n",
    "    return motivo_stop\n",
    "\n",
    "def test(X, Y, modelo: nn.Module, verbose=False, pred=False):\n",
    "    modelo.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_pred = modelo(X)\n",
    "        Y_pred = torch.softmax(Y_pred, dim=1)\n",
    "        Y_pred = torch.argmax(Y_pred, dim=1)\n",
    "        \n",
    "        if pred:\n",
    "            return Y_pred\n",
    "        else:\n",
    "            if torch.cuda.is_available():\n",
    "                Y_ = Y.cpu()\n",
    "                Y_pred = Y_pred.cpu()\n",
    "            else:\n",
    "                Y_ = Y\n",
    "            \n",
    "            f1 = f1_score(Y_, Y_pred, average='macro')\n",
    "            a = accuracy_score(Y_, Y_pred)\n",
    "            p = precision_score(Y_, Y_pred, average='macro')\n",
    "            r = recall_score(Y_, Y_pred, average='macro')\n",
    "            if verbose:\n",
    "                print(\"F1-score: \", f1)\n",
    "            return f1, a, p, r\n",
    "\n",
    "def test_fused(X_tfidf, X_we, Y, modelo: nn.Module, verbose=False, pred=False):\n",
    "    modelo.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_pred = modelo(X_tfidf, X_we)\n",
    "        Y_pred = torch.softmax(Y_pred, dim=1)\n",
    "        Y_pred = torch.argmax(Y_pred, dim=1)\n",
    "        \n",
    "        if pred:\n",
    "            return Y_pred\n",
    "        else:\n",
    "            if torch.cuda.is_available():\n",
    "                Y_ = Y.cpu()\n",
    "                Y_pred = Y_pred.cpu()\n",
    "            else:\n",
    "                Y_ = Y\n",
    "            \n",
    "            f1 = f1_score(Y_, Y_pred, average='macro')\n",
    "            a = accuracy_score(Y_, Y_pred)\n",
    "            p = precision_score(Y_, Y_pred, average='macro')\n",
    "            r = recall_score(Y_, Y_pred, average='macro')\n",
    "            if verbose:\n",
    "                print(\"F1-score: \", f1)\n",
    "            return f1, a, p, r\n",
    "\n",
    "def guardar_modelo(modelo_state: dict, caracteristicas: dict, filename_modelo: str, \n",
    "    filename_caracteristicas: str='./Resultados/DiccionarioModelos.txt', \n",
    "    file_mode='a'\n",
    "    ):\n",
    "    torch.save(modelo_state, filename_modelo)\n",
    "    with open(filename_caracteristicas, file_mode) as file:\n",
    "        file.write(f'{caracteristicas}\\n')\n",
    "\n",
    "def cargar_modelo(filename, caracteristicas: dict, gpu=True):\n",
    "    modelo = FeedForwardNeuralNetwork(caracteristicas['Entradas'], caracteristicas['Arquitectura'], caracteristicas['Salidas'])\n",
    "    modelo.load_state_dict(torch.load(filename, weights_only=True))\n",
    "    if torch.cuda.is_available() and gpu:\n",
    "        modelo.cuda()\n",
    "    return modelo\n",
    "\n",
    "def graficar(data, titulo, x_label, y_label, filename, color='aqua'):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.title(titulo)\n",
    "    plt.plot(np.arange(len(data)), data,  color=color, linestyle='-', linewidth=1, label=y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def guardar_predicciones(Y: Tensor, filename: str):\n",
    "    if torch.cuda.is_available():\n",
    "        Y = Y.cpu()\n",
    "    Y_np = Y.numpy()\n",
    "    Y_df = pd.DataFrame({\n",
    "        'id':range(1, len(Y_np) + 1),\n",
    "        'klass':Y_np\n",
    "        })\n",
    "    Y_df.to_csv(filename, index=False)\n",
    "    \n",
    "def graficar_conjunto(listas_modelos, nombres_labels, titulo, filename, epocas, opacidad=0.8, error_max=100_000, desc=''):\n",
    "    colores = ['black', 'darkred', 'forestgreen', 'darkviolet', 'darkorange', 'royalblue']\n",
    "    marcadores = ['solid', (0, (3, 1, 1, 1)), 'dotted', (0, (5, 1)), 'dashed', (0, (5, 10)), (5, (10, 3)), (0, (3, 5, 1, 5))]\n",
    "    i = 0\n",
    "    offset = len(colores) - len(listas_modelos)\n",
    "    patches = []\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.title(titulo)\n",
    "    n = 0\n",
    "    for lista in listas_modelos:    \n",
    "        color = colores[i + offset]\n",
    "        for diccionario in lista:\n",
    "            data = diccionario['HistorialPerdida']\n",
    "            if np.array(data).max() > error_max:\n",
    "                n += 1\n",
    "            else:\n",
    "                epocas_modelo = len(data)\n",
    "                epocas_faltantes = epocas - epocas_modelo\n",
    "                plt.plot(np.arange(epocas), data + [None]*epocas_faltantes, color=color, linestyle=marcadores[i], linewidth=1, alpha=opacidad)\n",
    "        patches.append(mpatches.Patch(color=color, label=nombres_labels[i]))\n",
    "        i += 1\n",
    "    plt.figtext(0.13, 0.03, f'{desc}')\n",
    "    plt.legend(handles=patches)\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Cross Entropy Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def promediar_resultados(listas_diccionarios, valores_posibles):\n",
    "    avgs = []\n",
    "    for lista in listas_diccionarios:\n",
    "        avg_f1 = [diccionario['HistorialF1'][-1] for diccionario in lista]\n",
    "        avgs.append(avg_f1)\n",
    "    avgs = np.array(avgs)\n",
    "    avgs = avgs.mean(axis=1)\n",
    "    print(avgs)\n",
    "    print(f'Mejor valor {avgs.max()} -> {valores_posibles[avgs.argmax()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff6029",
   "metadata": {},
   "source": [
    "<h2>Experimentación</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 200\n",
    "lr = 0.001\n",
    "batchs = [8, 16, 32, 64, 128]\n",
    "arquitectura = [64, 64, 64, 64, 64]\n",
    "vec = 'TF-IDF'\n",
    "features = 5_000\n",
    "\n",
    "k_folds = 8\n",
    "version = '1.1.3'\n",
    "n_exp = 0\n",
    "\n",
    "filename_train = './dataset_humor_train.json'\n",
    "filename_test = './dataset_humor_test.json'\n",
    "filename_grafica = f'./Resultados/Graficas/Shaw_v{version}'\n",
    "filename_modelo = f'./Resultados/Modelos/Shaw_v{version}'\n",
    "filename_prediccion =  f'./Resultados/Predicciones/Shaw_v{version}'\n",
    "filename_temp = f'./Resultados/Temp/Shaw_v{version}'\n",
    "\n",
    "diccionarios_k_folds = []\n",
    "listas_diccionarios = []\n",
    "Y_pred = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds)\n",
    "X, Y = leer_datos(filename_train)\n",
    "X_test_original, _ = leer_datos(filename_test)\n",
    "\n",
    "for batch in batchs:\n",
    "    for k, (index_train, index_test) in enumerate(skf.split(X, Y), start=1):                                                            # type: ignore\n",
    "        X_train, Y_train = X[index_train], Y[index_train]                                                                               # type: ignore\n",
    "        X_val, Y_val = X[index_test], Y[index_test]                                                                                     # type: ignore\n",
    "        Xs = vectorizar_TF_IDF([X_train, X_val, X_test_original], max_features=features)                                                 # type: ignore\n",
    "        X_smote, Y_smote = balancear(Xs[0], Y_train)                                                                                    # type: ignore\n",
    "        Xs_torch, Ys_torch = torchificar([X_smote, Xs[1], Xs[2]], [Y_smote, Y_val], vec, one_hot_encoding=True)                         # type: ignore\n",
    "        X_train = Xs_torch[0]\n",
    "        Y_train = Ys_torch[0]\n",
    "        X_val = Xs_torch[1]\n",
    "        Y_val = Ys_torch[1]\n",
    "        X_test = Xs_torch[2]\n",
    "        del Xs_torch\n",
    "        del Ys_torch\n",
    "        modelo = FeedForwardNeuralNetwork(X_train.shape[1], arquitectura, NUM_CLASES)\n",
    "        funcion_perdida = nn.CrossEntropyLoss()\n",
    "        optimizador = optim.Adam(modelo.parameters(), lr=lr)\n",
    "        caracteristicas = {\n",
    "                        'Version':version,\n",
    "                        'Vectorizacion':vec,\n",
    "                        'Entradas':X_train.shape[1],\n",
    "                        'Arquitectura':arquitectura,\n",
    "                        'Salidas':NUM_CLASES,\n",
    "                        'LearningRate':lr,\n",
    "                        'BatchSize':batch,\n",
    "                        'CapasOcultas':len(arquitectura),\n",
    "                        'K-Folds':k_folds,\n",
    "                    }\n",
    "        historial_perdida, historial_f1 = entrenar(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            modelo,\n",
    "            optimizador=optimizador,\n",
    "            funcion_perdida=funcion_perdida,\n",
    "            epocas=epocas,\n",
    "            batch_size=batch,\n",
    "            error_minimo=0.0001,\n",
    "            rango_epocas=15,\n",
    "            umbral_mejora=0.000001,\n",
    "            X_val=X_val,\n",
    "            Y_val=Y_val\n",
    "            )\n",
    "        print(f'F1: {historial_f1[-1]}')\n",
    "        caracteristicas.update({\n",
    "                        'K':k,\n",
    "                        'HistorialPerdida':historial_perdida,\n",
    "                        'HistorialF1':historial_f1,\n",
    "                    })\n",
    "        diccionarios_k_folds.append(caracteristicas)\n",
    "    listas_diccionarios.append(diccionarios_k_folds)\n",
    "    diccionarios_k_folds = []\n",
    "    n_exp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_conjunto(\n",
    "    listas_modelos=listas_diccionarios,\n",
    "    nombres_labels=batchs,\n",
    "    titulo='Shaw v1 por batch size',\n",
    "    filename=filename_grafica + '_batchs.png',\n",
    "    epocas=epocas\n",
    "    )\n",
    "promediar_resultados(listas_diccionarios, batchs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6a96c",
   "metadata": {},
   "source": [
    "<h2>Predicción</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 1000\n",
    "lr = 0.001\n",
    "batch = 32\n",
    "arquitectura = [64, 64, 64]\n",
    "vec = 'TF-IDF'\n",
    "features = 5_000\n",
    "\n",
    "version = '1.0.1'\n",
    "\n",
    "filename_grafica = f'./Resultados/Graficas/Shaw_v{version}.png'\n",
    "filename_modelo = f'./Resultados/Modelos/Shaw_v{version}.pth'\n",
    "filename_prediccion =  f'./Resultados/Predicciones/Shaw_v{version}.csv'\n",
    "\n",
    "X, Y = leer_datos(filename_train)\n",
    "X_test_original, _ = leer_datos(filename_test)\n",
    "Xs = vectorizar_TF_IDF([X, X_test_original], max_features=features)                                                                      # type: ignore\n",
    "X_smote, Y_smote = balancear(Xs[0], Y)                                                                                        # type: ignore\n",
    "Xs_torch, Ys_torch = torchificar([X_smote, Xs[1]], [Y_smote], vec, one_hot_encoding=True)                                   # type: ignore\n",
    "X_train = Xs_torch[0]\n",
    "Y_train = Ys_torch[0]\n",
    "X_test = Xs_torch[1]\n",
    "del Xs_torch\n",
    "del Ys_torch\n",
    "modelo = FeedForwardNeuralNetwork(X_train.shape[1], arquitectura, NUM_CLASES)\n",
    "funcion_perdida = nn.CrossEntropyLoss()\n",
    "optimizador = optim.Adam(modelo.parameters(), lr=lr)\n",
    "caracteristicas = {\n",
    "                'Version':version,\n",
    "                'Vectorizacion':vec,\n",
    "                'Entradas':X_train.shape[1],\n",
    "                'Arquitectura':arquitectura,\n",
    "                'Salidas':NUM_CLASES,\n",
    "                'LearningRate':lr,\n",
    "                'BatchSize':batch,\n",
    "                'CapasOcultas':len(arquitectura)\n",
    "            }\n",
    "historial_perdida, _ = entrenar(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    modelo,\n",
    "    evaluar=False,\n",
    "    optimizador=optimizador,\n",
    "    funcion_perdida=funcion_perdida,\n",
    "    epocas=epocas,\n",
    "    batch_size=batch,\n",
    "    error_minimo=0.0001,\n",
    "    rango_epocas=15,\n",
    "    umbral_mejora=0.000001\n",
    "    )\n",
    "Y_pred = test(X_test, [], modelo, pred=True) # type: ignore\n",
    "caracteristicas.update({\n",
    "                'HistorialPerdida':historial_perdida,\n",
    "                'Y_pred':Y_pred.cpu().numpy().tolist() # type: ignore\n",
    "            })\n",
    "guardar_modelo(\n",
    "    modelo.state_dict(), \n",
    "    caracteristicas, \n",
    "    filename_modelo=filename_modelo, \n",
    "    filename_caracteristicas='./Resultados/DiccionarioModelos.txt'\n",
    "    )\n",
    "guardar_predicciones(Y_pred, filename_prediccion)   # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c41dc8",
   "metadata": {},
   "source": [
    "<h1>Arquitectura convolucional</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424bcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_sizes: list[int], output_size: int, batch):\n",
    "        super().__init__()\n",
    "        self.drop_input = nn.Dropout(0.2)\n",
    "        self.drop_hidden = nn.Dropout()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        padding = 0\n",
    "        kernel_size = 3\n",
    "        stride = 1\n",
    "        dilation = 1\n",
    "        self.conv1 = nn.Conv1d(1, out_channels=batch, kernel_size=kernel_size, stride= stride, padding=padding, dilation=dilation)\n",
    "        L1 = ((input_size + 2*padding - dilation * (kernel_size-1) -1 ) // stride ) + 1\n",
    "        \n",
    "        self.fcl1 = nn.Linear(batch * L1, hidden_sizes[0])\n",
    "        self.fcl2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fcl3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.fcl4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
    "        self.fcl5 = nn.Linear(hidden_sizes[3], hidden_sizes[4])\n",
    "        self.output = nn.Linear(hidden_sizes[4], output_size)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fcl1.weight)\n",
    "        nn.init.xavier_uniform_(self.fcl2.weight)\n",
    "        nn.init.xavier_uniform_(self.fcl3.weight)\n",
    "        nn.init.xavier_uniform_(self.fcl4.weight)\n",
    "        nn.init.xavier_uniform_(self.fcl5.weight)\n",
    "        nn.init.xavier_uniform_(self.output.weight)\n",
    "        \n",
    "        nn.init.zeros_(self.fcl1.bias)\n",
    "        nn.init.zeros_(self.fcl2.bias)\n",
    "        nn.init.zeros_(self.fcl3.bias)\n",
    "        nn.init.zeros_(self.fcl4.bias)\n",
    "        nn.init.zeros_(self.fcl5.bias)\n",
    "        nn.init.zeros_(self.output.bias)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        x = X\n",
    "        x = self.relu(self.conv1(x.unsqueeze(1)))\n",
    "        x = x.view(x.size(0), -1)  # Aplanar\n",
    "        x = self.relu(self.fcl1(self.drop_input(x)))\n",
    "        x = self.relu(self.fcl2(self.drop_hidden(x)))\n",
    "        x = self.relu(self.fcl3(self.drop_hidden(x)))\n",
    "        x = self.relu(self.fcl4(self.drop_hidden(x)))\n",
    "        x = self.relu(self.fcl5(self.drop_hidden(x)))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cefe1",
   "metadata": {},
   "source": [
    "<h2>Experimentación</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 200\n",
    "lr = 0.001\n",
    "batchs = [128]\n",
    "arquitectura = [64, 64, 64, 64, 64]\n",
    "vec = 'TF-IDF'\n",
    "features = 5_000\n",
    "\n",
    "k_folds = 8\n",
    "version = '2'\n",
    "n_exp = 0\n",
    "\n",
    "filename_train = './dataset_humor_train.json'\n",
    "filename_test = './dataset_humor_test.json'\n",
    "filename_grafica = f'./Resultados/Graficas/Shaw_v{version}'\n",
    "filename_modelo = f'./Resultados/Modelos/Shaw_v{version}'\n",
    "filename_prediccion =  f'./Resultados/Predicciones/Shaw_v{version}'\n",
    "filename_temp = f'./Resultados/Temp/Shaw_v{version}'\n",
    "\n",
    "diccionarios_k_folds = []\n",
    "listas_diccionarios = []\n",
    "Y_pred = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds)\n",
    "X, Y = leer_datos(filename_train)\n",
    "X_test_original, _ = leer_datos(filename_test)\n",
    "\n",
    "for batch in batchs:\n",
    "    for k, (index_train, index_test) in enumerate(skf.split(X, Y), start=1):                                                            # type: ignore\n",
    "        X_train, Y_train = X[index_train], Y[index_train]                                                                               # type: ignore\n",
    "        X_val, Y_val = X[index_test], Y[index_test]                                                                                     # type: ignore\n",
    "        Xs = vectorizar_TF_IDF([X_train, X_val, X_test_original], max_features=features)                                                 # type: ignore\n",
    "        X_smote, Y_smote = balancear(Xs[0], Y_train)                                                                                    # type: ignore\n",
    "        Xs_torch, Ys_torch = torchificar([X_smote, Xs[1], Xs[2]], [Y_smote, Y_val], vec, one_hot_encoding=True)                         # type: ignore\n",
    "        X_train = Xs_torch[0]\n",
    "        Y_train = Ys_torch[0]\n",
    "        X_val = Xs_torch[1]\n",
    "        Y_val = Ys_torch[1]\n",
    "        X_test = Xs_torch[2]\n",
    "        del Xs_torch\n",
    "        del Ys_torch\n",
    "        modelo = ConvNeuralNetwork(X_train.shape[1], arquitectura, NUM_CLASES)\n",
    "        funcion_perdida = nn.CrossEntropyLoss()\n",
    "        optimizador = optim.Adam(modelo.parameters(), lr=lr)\n",
    "        caracteristicas = {\n",
    "                        'Version':version,\n",
    "                        'Vectorizacion':vec,\n",
    "                        'Entradas':X_train.shape[1],\n",
    "                        'Arquitectura':arquitectura,\n",
    "                        'Salidas':NUM_CLASES,\n",
    "                        'LearningRate':lr,\n",
    "                        'BatchSize':batch,\n",
    "                        'CapasOcultas':len(arquitectura),\n",
    "                        'K-Folds':k_folds,\n",
    "                    }\n",
    "        historial_perdida, historial_f1 = entrenar(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            modelo,\n",
    "            optimizador=optimizador,\n",
    "            funcion_perdida=funcion_perdida,\n",
    "            epocas=epocas,\n",
    "            batch_size=batch,\n",
    "            error_minimo=0.0001,\n",
    "            rango_epocas=15,\n",
    "            umbral_mejora=0.000001,\n",
    "            X_val=X_val,\n",
    "            Y_val=Y_val\n",
    "            )\n",
    "        print(f'F1: {historial_f1[-1]}')\n",
    "        caracteristicas.update({\n",
    "                        'K':k,\n",
    "                        'HistorialPerdida':historial_perdida,\n",
    "                        'HistorialF1':historial_f1,\n",
    "                    })\n",
    "        diccionarios_k_folds.append(caracteristicas)\n",
    "    listas_diccionarios.append(diccionarios_k_folds)\n",
    "    diccionarios_k_folds = []\n",
    "    n_exp += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4e749",
   "metadata": {},
   "source": [
    "<h1>Arquitectura de fusión simple</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eeff1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size_tfidf: int, input_size_embeddings: int, hidden_sizes: list[int], output_size: int):\n",
    "        super().__init__()\n",
    "        self.fcl = nn.ModuleList()\n",
    "        self.act = nn.ModuleList()\n",
    "        self.drop = nn.ModuleList()\n",
    "        self.drop.append(nn.Dropout(0.2)) #Input layers\n",
    "        # 2 capas de input\n",
    "        self.fcl_tfidf = nn.Linear(input_size_tfidf, hidden_sizes[0] // 2)\n",
    "        self.fcl_embeddings = nn.Linear(input_size_embeddings, hidden_sizes[0] // 2)\n",
    "        \n",
    "        # Las capas se forman por pares de numeros, en total 1 par menos que la lista neuronas\n",
    "        neuronas = hidden_sizes + [output_size]\n",
    "        for i in range(len(neuronas) - 1):\n",
    "            self.fcl.append(nn.Linear(neuronas[i], neuronas[i + 1]))\n",
    "            nn.init.xavier_uniform_(self.fcl[i].weight)                                                                                                 # type: ignore\n",
    "            nn.init.zeros_(self.fcl[i].bias)                                                                                                            # type: ignore\n",
    "        #Al aplicar CrossEntropy se necesita una función de activación menos que de capas\n",
    "        for i in range(len(neuronas) - 2):\n",
    "            self.act.append(nn.ReLU())\n",
    "            self.drop.append(nn.Dropout())\n",
    "    \n",
    "    def forward(self, X_tfidf, X_embeddings):\n",
    "        x_tfidf = self.act[0](self.fcl_tfidf(X_tfidf))\n",
    "        x_embeddings = self.act[0](self.fcl_embeddings(X_embeddings))\n",
    "        x = torch.cat((x_tfidf, x_embeddings), dim=1)\n",
    "        for i in range(len(self.act)):\n",
    "            x = self.drop[i](x)\n",
    "            x = self.fcl[i](x)\n",
    "            x = self.act[i](x)\n",
    "            \n",
    "        x = self.fcl[-1](x)     #No activar la última capa ni hacer dropout\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7dbf9a",
   "metadata": {},
   "source": [
    "<h2>Experimentación</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d8a0199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando:  32%|███▏      | 158/500 [00:40<01:27,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.790438984270587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  21%|██▏       | 107/500 [00:26<01:37,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.789612097304405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  32%|███▏      | 158/500 [00:38<01:23,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7852290159982467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 140/500 [00:33<01:25,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.788279531692207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 138/500 [00:32<01:26,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7860982265922145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  29%|██▉       | 146/500 [00:34<01:24,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7708550999665948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  31%|███       | 155/500 [00:37<01:22,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7957318712035693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  26%|██▌       | 131/500 [00:31<01:28,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7625695871309905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  31%|███       | 155/500 [00:36<01:22,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.8045751633986928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  30%|███       | 150/500 [00:35<01:23,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7686357535251221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 139/500 [00:33<01:26,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7844633314017126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▍       | 123/500 [00:29<01:29,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7652824707378563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▍       | 124/500 [00:29<01:29,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.785736723795381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  26%|██▌       | 130/500 [00:30<01:27,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7693221559506194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▌       | 125/500 [00:29<01:29,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7750576775185849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  29%|██▉       | 144/500 [00:34<01:24,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7991114545103342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  26%|██▌       | 129/500 [00:30<01:27,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.791814922376018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  33%|███▎      | 163/500 [00:38<01:19,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7665858694676362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  35%|███▌      | 175/500 [00:41<01:16,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.78250993344054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  23%|██▎       | 114/500 [00:26<01:31,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7629489555149402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▍       | 124/500 [00:29<01:29,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7930400010835602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 142/500 [00:33<01:24,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7793277310924369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  33%|███▎      | 164/500 [00:38<01:19,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7812950951965102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  21%|██▏       | 107/500 [00:25<01:33,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7554498027738898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  29%|██▉       | 144/500 [00:34<01:24,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7874580761885199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 138/500 [00:32<01:24,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7828801219373773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  26%|██▌       | 130/500 [00:30<01:27,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7963781920795094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  23%|██▎       | 114/500 [00:26<01:31,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7596925621442818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  24%|██▎       | 118/500 [00:27<01:30,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7887057602685562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  24%|██▍       | 121/500 [00:28<01:29,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7627615031972744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  24%|██▍       | 122/500 [00:28<01:29,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7935847298977997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  18%|█▊        | 90/500 [00:21<01:37,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7969486514378156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  30%|██▉       | 148/500 [00:34<01:22,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7754703402899146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 139/500 [00:32<01:25,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7680724198510795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  27%|██▋       | 135/500 [00:32<01:26,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7803163077077522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  30%|██▉       | 149/500 [00:35<01:22,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.8022835799197057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  31%|███       | 154/500 [00:36<01:21,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7935816803741331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 138/500 [00:32<01:25,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7718529807844705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▌       | 126/500 [00:29<01:28,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7832005990061943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▌       | 125/500 [00:29<01:28,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7730230106570473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  26%|██▌       | 128/500 [00:30<01:27,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.800038454143434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  26%|██▌       | 131/500 [00:30<01:26,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7637224298745475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  28%|██▊       | 140/500 [00:33<01:25,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7846526927169879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  30%|███       | 151/500 [00:35<01:21,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7721782540365206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  19%|█▉        | 94/500 [00:22<01:36,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.780398084039964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  25%|██▍       | 123/500 [00:29<01:28,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7873606730609617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  29%|██▉       | 145/500 [00:34<01:23,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7844788650070406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  27%|██▋       | 136/500 [00:32<01:25,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7590875755506663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  33%|███▎      | 164/500 [00:37<01:17,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7906481551728498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando:  29%|██▉       | 146/500 [00:33<01:20,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n",
      "F1: 0.7695359194998704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epocas = 500\n",
    "lr = 0.001\n",
    "batch = 128\n",
    "arquitecturas = [[256, 64, 256, 256, 32], [256, 64, 256, 128, 32], [256, 64, 256, 64, 32], [256, 64, 256, 32, 32], [256, 64, 256, 16, 32]]\n",
    "vec_tfidf = 'TF-IDF'\n",
    "vec_we = 'Embeddings'\n",
    "variantes = 'GEN'\n",
    "features = 300\n",
    "\n",
    "k_folds = 10\n",
    "version = '3.6'\n",
    "n_exp = 0\n",
    "\n",
    "filename_train = './dataset_humor_train_embeddings.json'\n",
    "filename_grafica = f'./Resultados/Graficas/Shaw_v{version}'\n",
    "filename_modelo = f'./Resultados/Modelos/Shaw_v{version}'\n",
    "filename_prediccion =  f'./Resultados/Predicciones/Shaw_v{version}'\n",
    "filename_temp = f'./Resultados/Temp/Shaw_v{version}'\n",
    "\n",
    "diccionarios_k_folds = []\n",
    "listas_diccionarios = []\n",
    "Y_pred = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds)\n",
    "X_we, Y = leer_datos_embeddings(filename_train, vec_we)\n",
    "X_tfidf, _ = leer_datos(filename_train)\n",
    "\n",
    "for arquitectura in arquitecturas:\n",
    "    for k, (index_train, index_test) in enumerate(skf.split(X_tfidf, Y), start=1):                      # type: ignore\n",
    "        X_train_tfidf, X_train_we, Y_train = X_tfidf[index_train], X_we[index_train], Y[index_train]\n",
    "        X_val_tfidf, X_val_we,  Y_val = X_tfidf[index_test], X_we[index_test],  Y[index_test]\n",
    "        Xs_tfidf = vectorizar_TF_IDF([X_train_tfidf, X_val_tfidf], max_features=features)\n",
    "        X_smote_tfidf, Y_smote = balancear(Xs_tfidf[0], Y_train)                                              # type: ignore\n",
    "        X_smote_we, _  = balancear(X_train_we, Y_train)                                                         # type: ignore\n",
    "        Xs_torch_tfidf, Ys_torch = torchificar([X_smote_tfidf, Xs_tfidf[1]], [Y_smote, Y_val], vec_tfidf, one_hot_encoding=True)\n",
    "        Xs_torch_we, _ = torchificar([X_smote_we, X_val_we], [Y_smote], vec_we, one_hot_encoding=True)\n",
    "        X_train_tfidf, X_val_tfidf = tuple(Xs_torch_tfidf)\n",
    "        X_train_we, X_val_we = tuple(Xs_torch_we)\n",
    "        Y_train, Y_val = tuple(Ys_torch)\n",
    "        del Xs_torch_tfidf\n",
    "        del Xs_torch_we\n",
    "        del Ys_torch\n",
    "        modelo = FusedNeuralNetwork(X_train_tfidf.shape[1], X_train_we.shape[1], arquitectura, NUM_CLASES)\n",
    "        funcion_perdida = nn.CrossEntropyLoss()\n",
    "        optimizador = optim.Adam(modelo.parameters(), lr=lr)\n",
    "        caracteristicas = {\n",
    "                        'Version':version,\n",
    "                        'Vectorizacion':(vec_tfidf, vec_we),\n",
    "                        'Entradas':(X_train_tfidf.shape[1], X_train_we.shape[1]),\n",
    "                        'Arquitectura':arquitectura,\n",
    "                        'Salidas':NUM_CLASES,\n",
    "                        'LearningRate':lr,\n",
    "                        'BatchSize':batch,\n",
    "                        'CapasOcultas':len(arquitectura) + 1,\n",
    "                        'K-Folds':k_folds,\n",
    "                    }\n",
    "        historial_perdida, historial_f1 = entrenar_fused(\n",
    "            X_train_tfidf,\n",
    "            X_train_we,\n",
    "            Y_train,\n",
    "            modelo,\n",
    "            optimizador=optimizador,\n",
    "            funcion_perdida=funcion_perdida,\n",
    "            epocas=epocas,\n",
    "            batch_size=batch,\n",
    "            error_minimo=0.0001,\n",
    "            rango_epocas=15,\n",
    "            umbral_mejora=0.000001,\n",
    "            X_val_tfidf=X_val_tfidf,\n",
    "            X_val_we=X_val_we,\n",
    "            Y_val=Y_val\n",
    "            )\n",
    "        print(f'F1: {historial_f1[-1]}')\n",
    "        caracteristicas.update({\n",
    "                        'K':k,\n",
    "                        'HistorialPerdida':historial_perdida,\n",
    "                        'HistorialF1':historial_f1,\n",
    "                    })\n",
    "        diccionarios_k_folds.append(caracteristicas)\n",
    "    listas_diccionarios.append(diccionarios_k_folds)\n",
    "    diccionarios_k_folds = []\n",
    "    n_exp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b43478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79026219 0.78320559 0.78204189 0.78426785]\n",
      "Mejor valor 0.7902621946125264 -> [256, 64, 256, 64, 32]\n"
     ]
    }
   ],
   "source": [
    "graficar_conjunto(\n",
    "    listas_modelos=listas_diccionarios,\n",
    "    nombres_labels=arquitecturas,\n",
    "    titulo='Shaw v3 tercera capa',\n",
    "    filename=filename_grafica + '_tercera_capa.png',\n",
    "    epocas=epocas\n",
    "    )\n",
    "promediar_resultados(listas_diccionarios, arquitecturas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76b8ca",
   "metadata": {},
   "source": [
    "<h2>Predicción</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e603156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando:  28%|██▊       | 140/500 [00:35<01:30,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paro por falta de mejora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epocas = 500\n",
    "lr = 0.001\n",
    "batch = 128\n",
    "arquitectura = [256, 64, 256, 64, 32]\n",
    "vec_tfidf = 'TF-IDF'\n",
    "vec_we = 'Embeddings'\n",
    "variantes = 'GEN'\n",
    "features = 300\n",
    "\n",
    "version = '3.5'\n",
    "intento = 4\n",
    "\n",
    "filename_test = './dataset_humor_test_embeddings.json'\n",
    "filename_train = './dataset_humor_train_embeddings.json'\n",
    "filename_grafica = f'./Resultados/Graficas/Shaw_v{version}_t{intento}'\n",
    "filename_modelo = f'./Resultados/Modelos/Shaw_v{version}_t{intento}.pth'\n",
    "filename_prediccion =  f'./Resultados/Predicciones/Shaw_v{version}_t{intento}.csv'\n",
    "filename_temp = f'./Resultados/Temp/Shaw_v{version}'\n",
    "\n",
    "X_train_we, Y_train = leer_datos_embeddings(filename_train, vec_we)\n",
    "X_train_tfidf, _ = leer_datos(filename_train)\n",
    "X_test_we_original, _ = leer_datos_embeddings(filename_test, vec_we)\n",
    "X_test_tfidf_original, _ = leer_datos(filename_test)\n",
    "\n",
    "Xs_tfidf = vectorizar_TF_IDF([X_train_tfidf, X_test_tfidf_original], max_features=features)\n",
    "X_smote_tfidf, Y_smote = balancear(Xs_tfidf[0], Y_train)                                              # type: ignore\n",
    "X_smote_we, _  = balancear(X_train_we, Y_train)                                                       # type: ignore\n",
    "\n",
    "Xs_torch_tfidf, Ys_torch = torchificar([X_smote_tfidf, Xs_tfidf[1]], [Y_smote], vec_tfidf, one_hot_encoding=True)\n",
    "Xs_torch_we, _ = torchificar([X_smote_we, X_test_we_original], [Y_smote], vec_we, one_hot_encoding=True)\n",
    "X_train_tfidf, X_test_tfidf = tuple(Xs_torch_tfidf)\n",
    "X_train_we, X_test_we = tuple(Xs_torch_we)\n",
    "Y_train = Ys_torch[0]\n",
    "del Xs_torch_tfidf\n",
    "del Xs_torch_we\n",
    "del Ys_torch\n",
    "modelo = FusedNeuralNetwork(X_train_tfidf.shape[1], X_train_we.shape[1], arquitectura, NUM_CLASES)\n",
    "funcion_perdida = nn.CrossEntropyLoss()\n",
    "optimizador = optim.Adam(modelo.parameters(), lr=lr)\n",
    "caracteristicas = {\n",
    "                'Version':version,\n",
    "                'Vectorizacion':(vec_tfidf, vec_we),\n",
    "                'Entradas':(X_train_tfidf.shape[1], X_train_we.shape[1]),\n",
    "                'Arquitectura':arquitectura,\n",
    "                'Salidas':NUM_CLASES,\n",
    "                'LearningRate':lr,\n",
    "                'BatchSize':batch,\n",
    "                'CapasOcultas':len(arquitectura) + 1,\n",
    "                'Random_seed':RANDOM_STATE\n",
    "            }\n",
    "historial_perdida, _ = entrenar_fused(\n",
    "    X_train_tfidf,\n",
    "    X_train_we,\n",
    "    Y_train,\n",
    "    modelo,\n",
    "    optimizador=optimizador,\n",
    "    funcion_perdida=funcion_perdida,\n",
    "    epocas=epocas,\n",
    "    batch_size=batch,\n",
    "    error_minimo=0.0001,\n",
    "    rango_epocas=15,\n",
    "    umbral_mejora=0.000001,\n",
    "    evaluar=False\n",
    "    )\n",
    "Y_pred = test_fused(X_test_tfidf, X_test_we, [], modelo, pred=True)\n",
    "caracteristicas.update({\n",
    "                'HistorialPerdida':historial_perdida,\n",
    "                'Y_pred':Y_pred.cpu().numpy().tolist() # type: ignore\n",
    "            })\n",
    "guardar_modelo(\n",
    "    modelo.state_dict(), \n",
    "    caracteristicas, \n",
    "    filename_modelo=filename_modelo, \n",
    "    filename_caracteristicas='./Resultados/DiccionarioModelos.txt'\n",
    "    )\n",
    "guardar_predicciones(Y_pred, filename_prediccion)   # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
