{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica. \n",
    "\n",
    "### Construir la siguiente red de perceptrones para identificar números de una matriz de 5x3 pixeles representados por 0s y 1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/fig-num_perceptron.png\" width=\"60%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de entrada: X\n",
    "####  Cada fila representa un número entre 0 y 9 codificado en bits en una 'matriz' de 5x3\n",
    "\n",
    "### Datos de Salida: T\n",
    "####  Cada fila representa un número entre 0 y 9 codificado en forma binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos de entrada (cada fila representa un número en bits)\n",
    "X = np.array([\n",
    "    [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
    "    [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# Salida deseada de la red neuronal\n",
    "T = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los datos para la comprensión del dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convertir la matriz numpy a una imagen\n",
    "# Visualización del  numero N\n",
    "N=9\n",
    "numero = X[N]   \n",
    "print(numero)\n",
    "bit_image = np.array( numero, dtype=np.uint8).reshape(5,3)  \n",
    "bit_image = bit_image  * 143 # Multiplicamos por 143 para convertir a escala de grises\n",
    "print(bit_image)\n",
    "plt.imshow(bit_image, cmap='gray',  vmin=0, vmax=255)\n",
    "plt.axis('off')  # Ocultar los ejes\n",
    "# plt.savefig(\"test.png\", bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La función de activación será la función escalón $ f(x) $, se define como sigue:\n",
    "\n",
    "$$\n",
    "f(x) = \n",
    "\\begin{cases} \n",
    "1 & \\text{si } x \\geq 0 \\\\\n",
    "0 & \\text{si } x < 0 \n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones:\n",
    "### - Implementar la red de perceptrones como se muestra en la figura anterior. \n",
    "### - En la siguiente clase, se proporciona un esquema general de la clase PerceptronTODO.\n",
    "### - Completar lo indicado en la clase para construir una clasificador usando la red de perceptrones mencionado.\n",
    "### - Aplicar el procedimiento para el entrenamiento del clasificador\n",
    "### - Haga uso de la regla de aprendizaje del perceptron para actualización de los pesos.\n",
    "\n",
    "$$\n",
    "w_i \\leftarrow w_i + \\eta \\cdot (t - y ) \\cdot x_i \\\\\n",
    "\n",
    "b \\leftarrow b + \\eta \\cdot (t - y)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PerceptronTODO:\n",
    "    def __init__(self, input_dim, output_dim, learning_rate=1, epochs=1000):\n",
    "        # Inicializa las dimensiones de entrada y salida, la tasa de aprendizaje y el número de épocas\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        # TODO: Inicializa la matriz de pesos (zeros o con valores aleatorios)\n",
    "        \n",
    "        # self.weights = ?\n",
    "\n",
    "        # TODO: Inicializa el sesgo (bias) con ceros o con valores aleatorios\n",
    "        \n",
    "        #self.bias = ?\n",
    "\n",
    "    def step_function(self, x):\n",
    "        # TODO: Implementa la función escalón \n",
    "        # return ?\n",
    "        return \n",
    "\n",
    "    def fit(self, X, T):\n",
    "\n",
    "        # Etapa de entrenamiento.\n",
    "        # X: contiene todo el conjunto de entrenamiento.\n",
    "        # T: contienen todas las salidas esperadas.\n",
    "\n",
    "        # Una época indica que pasó por todos los ejemplos de entrenamiento \n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            print(\"Epoca: \",  _)\n",
    "            # TODO: Propagación hacia adelante, calcula la entrada neta (z) de las neuronas\n",
    "\n",
    "            # z = ??????\n",
    "\n",
    "\n",
    "            # TODO: Calcula la salida aplicando la función escalón como función de activación\n",
    "\n",
    "            #  y = ?\n",
    "            \n",
    "            # TODO: Calcula el error como la diferencia entre la salida deseada T y la salida actual\n",
    "               # err = \n",
    "\n",
    "            # TODO: Actualiza los pesos usando la regla de aprendizaje del perceptrón\n",
    "\n",
    "            \n",
    "\n",
    "            # TODO: Actualiza el sesgo usando la regla de aprendizaje del perceptrón\n",
    "            \n",
    "\n",
    "    def predict(self, X):\n",
    "        # Etap\n",
    "        # TODO: Calcula la entrada neta de las neuronas (z) y devuelve la predicción aplicando la función de activación\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso para el entrenamiento  de la clase PerceptronTODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el perceptrón\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = T.shape[1]\n",
    "perceptron = PerceptronTODO(input_dim=input_dim, output_dim=output_dim, learning_rate=1, epochs=1000)\n",
    "\n",
    "# Entrenar el modelo\n",
    "# Encuentra los valores obtimos para los parámetros (pesos y bias):  W y B\n",
    "perceptron.fit(X, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de la etapa de predicción de nuevos datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones\n",
    "n8 = np.array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]) #8\n",
    "\n",
    "predictions = perceptron.predict(n8)\n",
    "\n",
    "# Imprimir las predicciones\n",
    "print(\"Predicciones:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio extra: Graficar el error de la etapa de entrenamiento.\n",
    "\n",
    "### - El eje x indicaría la época.\n",
    "\n",
    "### - El eje y indicaría el error.\n",
    "\n",
    "### - El error se puede calcular por medio del Error Cuadrático Medio (MSE) o el Error Absoluto Medio (MAE). Básicamente se calculan los errores de todos los ejemplos de entrenamiento para una época y se promedian. Estos se acumulan en un error general para graficarlos posteriormente al finalizar el entrenamiento. \n",
    "\n",
    "### - Graficar las dos medidas en gráficos independientes.\n",
    "\n",
    "\n",
    "## Error Cuadrático Medio (MSE)\n",
    "\n",
    "El Error Cuadrático Medio mide el promedio de los errores al cuadrado entre las predicciones del modelo y los valores reales. La fórmula es:\n",
    "\n",
    "$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (t_i - y_i)^2\n",
    "$\n",
    "\n",
    "Donde:\n",
    "- $ n $ es el número total de muestras o ejemplos de entrenamiento.\n",
    "- $ t_i $ es el valor real para la muestra $ i $.\n",
    "- $ y_i $ es el valor predicho para la muestra $ i $.\n",
    "\n",
    "## Error Absoluto Medio (MAE)\n",
    "\n",
    "El Error Absoluto Medio mide el promedio de los errores absolutos entre las predicciones del modelo y los valores reales. Es menos sensible a los valores atípicos en comparación con el MSE. La fórmula es:\n",
    "\n",
    "$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |t_i - y_i|\n",
    "$\n",
    "\n",
    "Donde:\n",
    "- $ n $ es el número total de muestras o ejemplos de entrenamiento.\n",
    "- $ t_i $ es el valor real para la muestra $ i $.\n",
    "- $ y_i $ es el valor predicho para la muestra $ i $.\n",
    "\n",
    "### Diferencias Clave:\n",
    "\n",
    "- **MSE** penaliza más los errores grandes debido a la elevación al cuadrado de las diferencias. Esto puede hacer que el modelo se enfoque en minimizar errores grandes, pero puede ser más sensible a los valores atípicos.\n",
    "\n",
    "- **MAE** da una medida más robusta de los errores, ya que no eleva al cuadrado las diferencias, por lo que es menos sensible a los valores atípicos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
