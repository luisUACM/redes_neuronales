{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Fusión\n",
    "\n",
    "- ### Arquitecturas diseñadas para combinar información de diferentes fuentes o tipos de datos, integrando varias representaciones de entrada para mejorar el rendimiento del modelo.\n",
    "- ### La fusión puede ocurrir en diferentes niveles de la red, ya sea en las capas de entrada, en capas intermedias. \n",
    "- ### Estos modelos permiten que las redes neuronales aprendan relaciones más complejas entre los distintos tipos de datos.\n",
    "- ### Es útil en tareas como la clasificación multimodal (imágenes, audio, texto), la generación de texto o la visión por computadora, donde se combinan distintos tipos de entradas.\n",
    "- ### También es útil para combinar representaciones distintas de la misma fuente de información.\n",
    "\n",
    "<img src=\"figs/fig-modelo_fusion1.png\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones de fusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Tensores de ejemplo (3 características de diferentes fuentes)\n",
    "tensor_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)  # (2, 2)\n",
    "tensor_b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)  # (2, 2)\n",
    "tensor_c = torch.tensor([[9, 10], [11, 12]], dtype=torch.float32)  # (2, 2)\n",
    "\n",
    "# Fusión de tensores por suma\n",
    "tensor_sum = tensor_a + tensor_b + tensor_c\n",
    "print(\"Fusión por suma:\")\n",
    "print(tensor_sum)\n",
    "\n",
    "# Fusión de tensores por concatenación en la dimensión 1\n",
    "tensor_concat = torch.cat((tensor_a, tensor_b, tensor_c), dim=1)  # Concatenar columnas\n",
    "print(\"\\nFusión por concatenación:\")\n",
    "print(tensor_concat)\n",
    "\n",
    "# Fusión con media\n",
    "tensor_mean = torch.mean(torch.stack([tensor_a, tensor_b, tensor_c]), dim=0)\n",
    "print(\"\\nFusión por promedio:\")\n",
    "print(tensor_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusión de representaciones por concatenación de características\n",
    "\n",
    "<img src=\"figs/fig-modelo_fusion1.png\" width=\"50%\">\n",
    "\n",
    "</br>\n",
    "<img src=\"figs/fig-modelo_fusion2.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Simular datos de texto\n",
    "num_samples = 100  # Número de documentos\n",
    "tfidf_dim = 5500     # Dimensión del vector TF-IDF\n",
    "embedding_dim = 300  # Dimensión del vector de embeddings\n",
    "\n",
    "# Generar datos simulados\n",
    "tfidf_vectors = torch.randn(num_samples, tfidf_dim)  # Vector TF-IDF simulado\n",
    "embedding_vectors = torch.randn(num_samples, embedding_dim)  # Vector de embeddings simulado\n",
    "\n",
    "# Fusionar las representaciones (Concatenación)\n",
    "# Dimensión final: (num_samples, tfidf_dim + embedding_dim)\n",
    "fused_vectors = torch.cat((tfidf_vectors, embedding_vectors), dim=1)  \n",
    "print(f\"Tamaño del vector fusionado: {fused_vectors.shape}\")\n",
    "\n",
    "# Etiquetas simuladas para clasificación binaria\n",
    "labels = torch.randint(0, 2, (num_samples,)).long()\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( fused_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un modelo simple\n",
    "class FusionSimple(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Inicializar el modelo\n",
    "# Dimensión del vector fusionado\n",
    "input_dim = tfidf_dim + embedding_dim  \n",
    "output_dim = 2  # Clasificación binaria\n",
    "model = FusionSimple(input_dim, output_dim)\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Época {epoch + 1}/{epochs}, Pérdida: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test)\n",
    "    y_pred_labels = torch.argmax(y_pred_test, dim=1)\n",
    "    accuracy = (y_pred_labels == y_test).float().mean()\n",
    "    print(f\"Precisión en prueba: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal con el manejo de multiples modalidades o representaciones con fusión intermedia\n",
    "#### Esta red usa representaciones TFIDF y Embeddings de 300 dimensiones\n",
    "\n",
    "<img src=\"figs/fig-modelo_fusion3.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Simular datos\n",
    "num_samples = 100  # Número de documentos\n",
    "tfidf_dim = 5500     # Dimensión del vector TF-IDF\n",
    "embedding_dim = 300  # Dimensión del vector de embeddings\n",
    "\n",
    "# Simular vectores TF-IDF y embeddings\n",
    "tfidf_vectors = torch.randn(num_samples, tfidf_dim)\n",
    "embedding_vectors = torch.randn(num_samples, embedding_dim)\n",
    "\n",
    "# Etiquetas simuladas\n",
    "labels = torch.randint(0, 2, (num_samples,)).long()\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "\n",
    "\n",
    "# Dividir los datos de manera consistente para entrenamiento y prueba\n",
    "X_tfidf_train, X_tfidf_test, X_embed_train, X_embed_test, y_train, y_test = train_test_split( tfidf_vectors, embedding_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el modelo con fusión en una capa intermedia\n",
    "class FusionIntermedia(nn.Module):\n",
    "    def __init__(self, tfidf_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Procesamiento inicial de TF-IDF\n",
    "        self.tfidf_fc = nn.Linear(tfidf_dim, hidden_dim)\n",
    "        # Procesamiento inicial de embeddings\n",
    "        self.embedding_fc = nn.Linear(embedding_dim, hidden_dim)\n",
    "        # Fusión\n",
    "        self.fusion_fc = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        # Clasificación final\n",
    "        self.output_fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, tfidf, embedding):\n",
    "        # Procesar por separado\n",
    "        tfidf_out = self.tfidf_fc(tfidf)\n",
    "        tfidf_out = self.relu(tfidf_out)\n",
    "\n",
    "        embedding_out = self.embedding_fc(embedding)\n",
    "        embedding_out = self.relu(embedding_out)\n",
    "\n",
    "        # Fusionar\n",
    "        fused = torch.cat((tfidf_out, embedding_out), dim=1)\n",
    "        fused_out = self.fusion_fc(fused)\n",
    "        fused_out = self.relu(fused_out)\n",
    "        # Clasificación\n",
    "        output = self.output_fc(fused_out)\n",
    "        output = self.sigmoid(fused_out)\n",
    "        return output\n",
    "\n",
    "# Inicializar el modelo\n",
    "hidden_dim = 128  # Dimensión intermedia\n",
    "output_dim = 2    # Clasificación binaria\n",
    "model = FusionIntermedia(tfidf_dim, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_tfidf_train, X_embed_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Época {epoch + 1}/{epochs}, Pérdida: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_tfidf_test, X_embed_test)\n",
    "    y_pred_labels = torch.argmax(y_pred_test, dim=1)\n",
    "    accuracy = (y_pred_labels == y_test).float().mean()\n",
    "    print(f\"Precisión en prueba: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.randint(0, 2, (num_samples,)).long()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de minibatches para multiples modalidades o representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Ejemplo de datos de entrada (con tamaño arbitrario para la demostración)\n",
    "N = 256  # Número de ejemplos\n",
    "tfidf_dim = 5500\n",
    "embedding_dim1 = 400\n",
    "batch_size = 64\n",
    "\n",
    "# Datos de ejemplo (generados aleatoriamente)\n",
    "tfidf_data = torch.rand(N, tfidf_dim)\n",
    "embedding1_data = torch.rand(N, embedding_dim1)\n",
    "labels = torch.randint(0, 2, (N,))\n",
    "\n",
    "# Función para crear minibatches\n",
    "def create_minibatches(X_tfidf, X_emb1, Y, batch_size):\n",
    "    # Cargar los datos en un dataset de tensores\n",
    "    dataset = TensorDataset(X_tfidf, X_emb1, Y)\n",
    "    \n",
    "    # Crear el DataLoader que divide los datos en minibatches\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# Crear el DataLoader para los minibatches\n",
    "loader = create_minibatches(tfidf_data, embedding1_data, labels, batch_size)\n",
    "\n",
    "# Ejemplo de cómo iterar a través de los minibatches\n",
    "batch=0\n",
    "for batch_tfidf, batch_emb1, batch_labels in loader:\n",
    "    print(f\"Batch: {batch}\")\n",
    "    print(f\"TF-IDF Batch Shape: {batch_tfidf.shape}\")\n",
    "    print(f\"Embedding1 Batch Shape: {batch_emb1.shape}\")\n",
    "    print(f\"Labels Batch Shape: {batch_labels.shape}\")\n",
    "    batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporación de minibatches para multiples modalidades o representaciones al entrenamiento de la red: TFIDF y Embeddings 300d\n",
    "<img src=\"figs/fig-modelo_fusion3.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Función para crear minibatches\n",
    "def create_minibatches(X_tfidf, X_emb1, Y, batch_size):\n",
    "    # Cargar los datos en un dataset de tensores\n",
    "    dataset = TensorDataset(X_tfidf, X_emb1, Y)\n",
    "    \n",
    "    # Crear el DataLoader que divide los datos en minibatches\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "\n",
    "# Simular datos\n",
    "num_samples = 100  # Número de documentos\n",
    "tfidf_dim = 5500     # Dimensión del vector TF-IDF\n",
    "embedding_dim = 300  # Dimensión del vector de embeddings\n",
    "batch_size = 64\n",
    "# Simular vectores TF-IDF y embeddings\n",
    "tfidf_vectors = torch.randn(num_samples, tfidf_dim)\n",
    "embedding_vectors = torch.randn(num_samples, embedding_dim)\n",
    "\n",
    "# Etiquetas simuladas\n",
    "labels = torch.randint(0, 2, (num_samples,)).long()\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "\n",
    "\n",
    "# Dividir los datos de manera consistente para entrenamiento y prueba\n",
    "# Se envian las dos matrices TFIDF y EMBEDDINGS \n",
    "X_tfidf_train, X_tfidf_test, X_embed_train, X_embed_test, y_train, y_test = train_test_split( tfidf_vectors, embedding_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el DataLoader para los minibatches\n",
    "loader = create_minibatches(X_tfidf_train, X_embed_train, y_train, batch_size)\n",
    "\n",
    "\n",
    "# Definir el modelo con fusión en una capa intermedia\n",
    "class FusionIntermedia(nn.Module):\n",
    "    def __init__(self, tfidf_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Procesamiento inicial de TF-IDF\n",
    "        self.tfidf_fc = nn.Linear(tfidf_dim, hidden_dim)\n",
    "        # Procesamiento inicial de embeddings\n",
    "        self.embedding_fc = nn.Linear(embedding_dim, hidden_dim)\n",
    "        # Fusión\n",
    "        self.fusion_fc = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        # Clasificación final\n",
    "        self.output_fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, tfidf, embedding):\n",
    "        # Procesar por separado\n",
    "        tfidf_out = self.relu(self.tfidf_fc(tfidf))\n",
    "        embedding_out = self.relu(self.embedding_fc(embedding))\n",
    "        # Fusionar\n",
    "        fused = torch.cat((tfidf_out, embedding_out), dim=1)\n",
    "        fused_out = self.relu(self.fusion_fc(fused))\n",
    "        # Clasificación\n",
    "        output = self.output_fc(fused_out)\n",
    "        return output\n",
    "\n",
    "# Inicializar el modelo\n",
    "hidden_dim = 128  # Dimensión intermedia\n",
    "output_dim = 2    # Clasificación binaria\n",
    "model = FusionIntermedia(tfidf_dim, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    batch=0\n",
    "    for X_tfidf_train_batch, X_embed_train_batch, y_train_batch in loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tfidf_train_batch, X_embed_train_batch)\n",
    "        loss = criterion(y_pred, y_train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Batch {batch}  Pérdida: {loss.item():.4f}\")\n",
    "        batch+=1\n",
    "    print(f\"Época {epoch + 1}/{epochs}, Pérdida: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_tfidf_test, X_embed_test)\n",
    "    y_pred_labels = torch.argmax(y_pred_test, dim=1)\n",
    "    accuracy = (y_pred_labels == y_test).float().mean()\n",
    "    print(f\"Precisión en prueba: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forma de los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train.shape, X_tfidf_test.shape, X_embed_train.shape, X_embed_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de multiples modalidades o representaciones al entrenamiento de la red: TFIDF, Embeddings 300d, Embeddings 100d\n",
    "\n",
    "<img src=\"figs/fig-modelo_fusion4.png\" width=\"50%\">\n",
    "\n",
    "</br>\n",
    "\n",
    "<img src=\"figs/fig-modelo_fusion5.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Simular datos\n",
    "num_samples = 100       # Número de documentos\n",
    "tfidf_dim = 5500          # Dimensión del vector TF-IDF\n",
    "embedding_dim1 = 300    # Dimensión del primer vector de embeddings\n",
    "embedding_dim2 = 100    # Dimensión del segundo vector de embeddings\n",
    "\n",
    "# Simular vectores TF-IDF y embeddings\n",
    "tfidf_vectors = torch.randn(num_samples, tfidf_dim)\n",
    "embedding_vectors1 = torch.randn(num_samples, embedding_dim1)\n",
    "embedding_vectors2 = torch.randn(num_samples, embedding_dim2)\n",
    "\n",
    "# Etiquetas simuladas\n",
    "labels = torch.randint(0, 2, (num_samples,)).long()\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_size = int(0.8 * num_samples)\n",
    "X_tfidf_train, X_tfidf_test = tfidf_vectors[:train_size], tfidf_vectors[train_size:]\n",
    "X_embed1_train, X_embed1_test = embedding_vectors1[:train_size], embedding_vectors1[train_size:]\n",
    "X_embed2_train, X_embed2_test = embedding_vectors2[:train_size], embedding_vectors2[train_size:]\n",
    "y_train, y_test = labels[:train_size], labels[train_size:]\n",
    "\n",
    "# Definir el modelo con tres entradas y fusión en capa intermedia\n",
    "class MultiplesEntradasFusion(nn.Module):\n",
    "    def __init__(self, tfidf_dim, embedding_dim1, embedding_dim2, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Procesamiento inicial de TF-IDF\n",
    "        self.tfidf_fc = nn.Linear(tfidf_dim, hidden_dim)\n",
    "        # Procesamiento inicial del primer embedding\n",
    "        self.embedding1_fc = nn.Linear(embedding_dim1, hidden_dim)\n",
    "        # Procesamiento inicial del segundo embedding\n",
    "        self.embedding2_fc = nn.Linear(embedding_dim2, hidden_dim)\n",
    "        # Fusión\n",
    "        self.fusion_fc = nn.Linear(3 * hidden_dim, hidden_dim)\n",
    "        # Clasificación final\n",
    "        self.output_fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, tfidf, embedding1, embedding2):\n",
    "        # Procesar cada entrada por separado\n",
    "        tfidf_out = self.relu(self.tfidf_fc(tfidf))\n",
    "        embedding1_out = self.relu(self.embedding1_fc(embedding1))\n",
    "        embedding2_out = self.relu(self.embedding2_fc(embedding2))\n",
    "        # Fusionar\n",
    "        fused = torch.cat((tfidf_out, embedding1_out, embedding2_out), dim=1)\n",
    "        fused_out = self.relu(self.fusion_fc(fused))\n",
    "        # Clasificación\n",
    "        output = self.output_fc(fused_out)\n",
    "        return output\n",
    "\n",
    "# Inicializar el modelo\n",
    "hidden_dim = 128  # Dimensión intermedia\n",
    "output_dim = 2    # Clasificación binaria\n",
    "model = MultiplesEntradasFusion(tfidf_dim, embedding_dim1, embedding_dim2, hidden_dim, output_dim)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_tfidf_train, X_embed1_train, X_embed2_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Época {epoch + 1}/{epochs}, Pérdida: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_tfidf_test, X_embed1_test, X_embed2_test)\n",
    "    y_pred_labels = torch.argmax(y_pred_test, dim=1)\n",
    "    accuracy = (y_pred_labels == y_test).float().mean()\n",
    "    print(f\"Precisión en prueba: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1 \n",
    "- ## Para la arquitectura MultiplesEntradasFusion: \n",
    "    ### 1. Crear los minibatches para organizar la separación de datos adecuadamente\n",
    "    ### 1.1. Usar 512 Ejemplos de entrenamiento\n",
    "    ### 1.1. Usar un batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2 \n",
    "- ## Para la arquitectura de red sobre el conjunto de datos de agresividad: \n",
    "    ### 1. Aplicar el modelo de fusión intermedia\n",
    "    - ### 1.1. Para la subred de TFIDF aplicar 3 capas ocultas\n",
    "    - ### 1.2. Para la subred de Embeddings de 300d aplicar 2 capas ocultas\n",
    "    - ### 1.3. Fusionar las salidas de 1.1 y 1.3, para posteriormente aplicar otra subred de 2 capas ocultas\n",
    "    - ### 1.4. Aplicar una capa de salida\n",
    "    ### 2. Evaluar el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3\n",
    "- ## Para la arquitectura del ejercicio 2\n",
    "    ### 1. Aplicar regularización en las diferentes capas ocultas (dropout)\n",
    "    ### 2. Evaluar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
